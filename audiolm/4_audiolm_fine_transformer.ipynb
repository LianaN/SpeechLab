{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n337KoD2om3L",
    "outputId": "97ada0c6-f21c-483e-d63d-08abddd49004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 24 15:23:24 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.182.03   Driver Version: 470.182.03   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000001:00:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    42W / 300W |      0MiB / 80994MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "# If this doesn't work, there's no GPU available or detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TLJAcUHpvmp4",
    "outputId": "95bcda95-a484-40c6-e5a7-47f4378759a8"
   },
   "outputs": [],
   "source": [
    "#%pip install audiolm-pytorch\n",
    "#%pip install pydub\n",
    "#%pip install scikit-learn==0.24.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuNcsDJsvQwh"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBxNK5cKW--_"
   },
   "source": [
    "### Imports & paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OrNeKngVVM0L"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import math\n",
    "import wave\n",
    "import struct\n",
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "from audiolm_pytorch import SoundStream, SoundStreamTrainer, HubertWithKmeans, SemanticTransformer, SemanticTransformerTrainer, HubertWithKmeans, CoarseTransformer, CoarseTransformerWrapper, CoarseTransformerTrainer, FineTransformer, FineTransformerWrapper, FineTransformerTrainer, AudioLM\n",
    "from torch import nn\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "\n",
    "# define all dataset paths, checkpoints, etc\n",
    "dataset_folder = \"audio/wav\"\n",
    "soundstream_ckpt = \"results/soundstream.8.pt\" # this can change depending on number of steps\n",
    "hubert_ckpt = 'hubert/hubert_base_ls960.pt'\n",
    "hubert_quantizer = f'hubert/hubert_base_ls960_L9_km500.bin' # listed in row \"HuBERT Base (~95M params)\", column Quantizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYcI0aXEwuxR"
   },
   "source": [
    "## Training\n",
    "\n",
    "Now that we have a dataset, we can train AudioLM.\n",
    "\n",
    "**Note**: do NOT type \"y\" to overwrite previous experiments/ checkpoints when running through the cells here unless you're ready to the entire results folder! Otherwise you will end up erasing things (e.g. you train SoundStream first, and if you choose \"overwrite\" then you lose the SoundStream checkpoint when you then train SemanticTransformer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRvj7qOJWzmw"
   },
   "source": [
    "### FineTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZRaEhRRKWg8F",
    "outputId": "7cc166c4-c8e9-45ef-8293-8f5381c2d3af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with dataset of 7827 samples and validating with randomly splitted 412 samples\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "do you want to clear previous experiment checkpoints and results? (y/n)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: loss: 73.48239326477051\n",
      "0: valid loss 80.79437255859375\n",
      "0: saving model to results\n",
      "1: loss: 68.14169573783875\n",
      "2: loss: 58.45275431871414\n",
      "3: loss: 55.95248901844025\n",
      "4: loss: 52.18133091926575\n",
      "5: loss: 45.070580422878265\n",
      "6: loss: 42.473953783512115\n",
      "7: loss: 38.600813537836075\n",
      "8: loss: 35.284226447343826\n",
      "training complete\n"
     ]
    }
   ],
   "source": [
    "soundstream = SoundStream(\n",
    "    codebook_size = 1024,\n",
    "    rq_num_quantizers = 8,\n",
    ")\n",
    "\n",
    "soundstream.load(f\"./{soundstream_ckpt}\")\n",
    "\n",
    "fine_transformer = FineTransformer(\n",
    "    num_coarse_quantizers = 3,\n",
    "    num_fine_quantizers = 5,\n",
    "    codebook_size = 1024,\n",
    "    dim = 512,\n",
    "    depth = 6\n",
    ")\n",
    "\n",
    "finetransformer_trainer = FineTransformerTrainer(\n",
    "    transformer = fine_transformer,\n",
    "    codec = soundstream,\n",
    "    folder = dataset_folder,\n",
    "    batch_size = 1,\n",
    "    grad_accum_every = 32,        # effective batch size of 32\n",
    "    data_max_length_seconds = 4,  # train on 4 second audio\n",
    "    num_train_steps = 9\n",
    ")\n",
    "# NOTE: I changed num_train_steps to 9 (aka 8 + 1) from 10000 to make things go faster for demo purposes\n",
    "# adjusting save_*_every variables for the same reason\n",
    "\n",
    "finetransformer_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "is9wLY_ncDYK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
